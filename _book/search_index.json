[["index.html", "How to calibrate protection vulnerability scoring? 1 Introduction", " How to calibrate protection vulnerability scoring? Field experience stocktaking - UNHCR V0.1 - Draft Version for peer review - as of 02 March 2021 1 Introduction As soon as a humanitarian situation is moving away from the emergency phase, when a caseload goes beyond a certain size and both budget and resources are limited, scoring systems are required to inform decision numerous type of individual/household level type of assistance allocation (Cash-based Interventions, distribution of core relief items, professional training, micro-credit and other livelihood intervention but also community leaders training…). Scores uses numerical tools to rank order cases using data integrated into a single value that attempts to measure vulnerability risk. Scoring systems are designed for lowering the cost of serving people in needs and increasing the quality of both services and beneficiary satisfaction. For humanitarian assistance, vulnerability scores are the main concept to allocate individual assistance, in a similar way credit scoring can be used to increase financial inclusions by micro-credit organizations. UNHCR/WFP Joint Guidance: Targeting of Assistance to Meet Basic Needs provides some elements on how to measure vulnerability from a protection angle: UNHCR measures indicators of refugee well-being including health and nutrition status, water and sanitation, shel-ter, socio- economic poverty and protection vulnerabilities to guide assistance and solution strategies. Analysis of individual protection vulnerabilities is guided by the Specific Needs approach, which guides case management.[…] In addition UNHCR promotes the inclusion of refugees into National Poverty Assessments so as to be able to generate comparable data between refugees and host communities. Comparable socio-economic data is increasingly important to ascertain the level of assistance needed and to inform regional area-based development programs implemented by development and private sector partners together with National Governments as part of the Global Compact for Refugees In addition the Basic Needs Approach in the Refugee Response outlines the need for a vulnerability framework and eligibility criteria: Vulnerability analysis framework: The framework defines which households are vulnerable among the entire refugee population. Various socio-economic or sector models can be applied as tools to prioritize who is eligible to receive assistance. An efficient tool for predicting the welfare of all refugee households is econometric welfare modelling. An example can be found in the Vulnerability Assessment Framework in Jordan Targeting: defining eligibility: Anchored in a rights-based approach, the identification and selection of individuals or households for appropriate assistance are based on multi-sectoral analysis of protection risks, wealth and food insecurity, the vulnerability framework and the identified needs. Information from monitoring is analysed and can be used to update targeting eligibility criteria and make other adjustments. Though, those guidance do not provide details on how the calculation shall be made. For instance, how to combine the occurrence of multiple specific needs within the same household? How to reflect the interaction between socio-economic vulnerability and protection risks into a single score? As a result, each operation has a different approach to measure “vulnerability” in order to prioritize and target assistance. In the lack of specific guidance, there are risks that the resulting scores actually capture very different concepts or that adequate statistical treatments are not implemented. Beyond this, the lack of detailed guidance make it difficult to build technical capacity for operations data expert to build those measurement. A standardized approach for the measurement of vulnerability, where the same formula could be applied universally and independently of the context is unlikely to be a robust approach. In the same joint guidance are referenced WFP Consolidated Approach for reporting indicators of food security, (CARI). Those provides details on how to build a composite indicator: the “Food Security Index”. In this approach, the theoretical model for the indicator is standardized while there’s also a process to customize it according to the context (aka a “calibration”). CARI Food Security Index theoretical model This document build on generic guidance on composite indicator development from the EU-joint Research Center on Composite Indicator and aims at providing a cookbook for field practitioners suggesting a similar approach than WFP, i.e. an harmonized theoretical model paired with a calibration process. The following is a compilation of field findings in relation with the challenges related to protection vulnerability measurement. It is open for peer-review and contributions can be made in different ways: Open a discussion point Report a bug or suggest an improvement in the attached statistical code Fork the document and suggest additional elements with pull request This document includes: An executive summary for Senior Management to understand what they need to know in terms of high level concepts on vulnerability scoring Contextual elements around scoring: why &amp; when, how and risks Hands-on tutorial for data experts on how to implement different approaches for calibration, using either expert opinions ( budget allocation, conjoint analysis or Analytic hierarchy process) or household survey data (Vulnerability proxy, Deprivation model or Item Response Theory) and to compare the results through a robustness and sensitivity analysis. Explanation on how to use resulting household vulnerability scores in relation with targeting on one side (i.e. eligibility of different population segments for different type of interventions) and prioritization (i.e. final selection of beneficiaries for interventions that required to identify household, like Cash-based interventions at first) All examples from this documents are build with a reproducible analysis approach, which implies for data expert on the field can simply adapt the scripts included in the documents to the context and data available in their own operations. Reference to related scripts are mentionned in each chapters "],["executive-summary-what-you-need-to-know-as-a-manager.html", " 2 Executive summary: what you need to know as a manager 2.1 There’s no simple solution to a complex problem 2.2 Scoring with a protection lens 2.3 The reliability of your scores will reflect the quality of your data 2.4 Be ready for auditing", " 2 Executive summary: what you need to know as a manager “Everything simple is false. Everything which is too complex is unusable.” Paul Valery, Œuvres II, 1942. 2.1 There’s no simple solution to a complex problem Numbers of humanitarian interventions in protracted context, such as Cash-based Interventions, distribution of core relief items, professional training, micro-credit and other livelihood intervention but also community leaders training, require targeting. In such context, it’s key to have organized tools to first profile the people in need that could be eligible for each type of assistance, and then to prioritize beneficiaries with a neutral and objective tool. Scores uses numerical tools to rank order cases using data integrated into a single value that attempts to measure vulnerability risk. Scoring systems are designed to better assess population profiles and are powerful tool to standardize decision-making when selecting beneficiaries. Such system improve the accuracy of allowance decisions and make assistance more cost-efficient. Operations sometimes assume that setting up a scoring system is too costly or difficult or that they do not have the kind of data needed to implement it. However, the primary input needed for to calibrate such scores are available in most operations: identified filed experts and a registration system. This documents explains how data from both experts and people in need can be used to develop scoring formula and the ways in which it can be used. Though setting up such scoring systems also requires specific efforts around: Systems business process, such as referral pathway, needs to be fully integrated, online and provide data in real time. Data needs to be captured digitally in real time, fully integrated, and managed by automated processes. For instance, scores values needs to be updates automatically whenever the data describing the case is changing. Information from the scores should be used across different sectors to drive strategy and support programs design, assistance delivery and risk management. While different types of assistance may have different eligibility and prioritization threshold, the way the score are defined should be consistent between all sectors to ensure consistency in the way programmes are designed. Analytics supports should be available to monitor and update the scoring models on regular basis. Last but not least, the way the scoring calculation are designed should reflect what the organisation is tying to address. 2.2 Scoring with a protection lens In UNHCR context, it’s important to define a scoring model that actually reflects UNHCR strategic directions and that can inform all potential type interventions that may require targeting Indeed not all type of interventions are linked to the need to target as some are linked to a systematic intervention (for instance SGBV) or look at a broader scale (like advocacy around legal environment). Protection egg This already suggest that using a protection lens, vulnerability is multidimensional. 2.3 The reliability of your scores will reflect the quality of your data 2.4 Be ready for auditing A lot of attention is now given to data responsibility "],["why-and-when-using-vulnerability-scoring.html", " 3 Why and when using vulnerability scoring? 3.1 from the identification of vulnerables to the scoring of household vulnerability 3.2 Different models of vulnerability: from food insecurity &amp; poverty to a “protection vulnerability framework”", " 3 Why and when using vulnerability scoring? 3.1 from the identification of vulnerables to the scoring of household vulnerability In a humanitarian environment, vulnerability may be defined differently, depending on the mandates of the humanitarian agencies, the intended impact and the definition of the population to be assisted. For instance, WFP measures food security through the Food Security Index (FSI), a composite indicator defined in the widely used Consolidated Approach for Reporting Indicators of Food Security. For the UNHCR, refugees’ vulnerability is identified in the frame of the protection risk analysis by looking at the concept of international protection, which put into context risk, threat, vulnerabilities, and capacities. This accounts for a case-specific condition related to household capacity, dependency level within the household and occurrence of specific needs, such as the occurrence of pressing medical needs, disabilities or individuals with particular constraints. __The Protection risk equation though “…not a mathematical equation [but] merely a tool that serves to illustrate that the protection risk faced by a given population is directly proportional to threats and to vulnerabilities, and inversely proportional to capacities” – EUROPEAN COMMISSION. DG ECHO 2016 - Humanitarian Protection: Improving protection outcomes to reduce risks for people in humanitarian crises The panorama of options for targeting approach has been already well documented (cf Review of Needs Assessment Tools, Response Analysis Frameworks, and Targeting Guidance for Urban Humanitarian Response). Simple targeting approaches (like categoric, administrative or geographic targeting) appears as easy options. Indeed there’s a real debate arguing for a better global efficiency of categoric targeting in the context of national protection system. Though those approaches comes with two important limitations: They do not offer the capacity to prioritize objectively individuals in case of limited budget. While they can be definitely ones during an initial emergency phase, likely only sovereign authority can sustain their funding in the long term. Agencies and organisation working in the context of time bounded programmes or projects that would use such approaches take the risk of creating cobra effects In this context, a significant challenge is to account for the combination and articulation of the various dimensions of vulnerability through scores. Vulnerability scores offers not only a way to prioritize household based on budget constraints but also to define population segment with a similar profile and for which distinct theories of change can be built. Each population segment shall be then targeted and prioritized with a combination of coordinated assistance and intervention types, coming from multiple agencies and varying from emergency support, unconditional assistance, training, livelihoods graduation or even micro-credit. 3.2 Different models of vulnerability: from food insecurity &amp; poverty to a “protection vulnerability framework” Higher expenditure = higher resilience? But where does this money come from? Children begging? Illegal work? UNHCR is not a poverty alleviation agency. Poverty alone cannot be our measurement. A framework to measure household ability to address different level of vulnerability. This framework aims at informing household targeting needs by articulating a series of potential assistance varying from In-kind distribution, Cash allowance, Livelihood support and Community building activities. Relevant to humanitarian settings: Multi-sectoral, applicable and adapted for joint, collaborative or multi stakeholder’s settings Providing analytical value: Leads to conclusions commonly required in needs analysis, targeting &amp; prioritization Reproducible: Documentation, expertise, tools and templates available to implement the framework in a systematic and rigorous way Authoritative: Approach reviewed by external peers "],["potential-approaches-to-calibrate-scores.html", " 4 Potential approaches to calibrate scores 4.1 Vulnerability as a latent variable 4.2 Avoid compensability effects 4.3 What data can be used?", " 4 Potential approaches to calibrate scores 4.1 Vulnerability as a latent variable Vulnerability is not observed, it’s a latent variable, an intellectual construction based on multiple criteria. The challenge is: Define the criteria Provide a measurement for each criteria Define relative weights to be used for each criteria 4.2 Avoid compensability effects Vulnerability scores are composite measurement (cf. Handbook on Constructing Composite Indicators: Methodology and User Guide, OECD/JRC 2008) obtained through combination of aggregated and weighted indicators. Due to the very nature of vulnerability, the sub-vulnerability indicators are unlikely to be fully substituable, i.e. one indicator is unlikely to fully compensate another one. For vulnerability scoring, weights are rather expected to refect the importance of each indicator. Therefore, it is advised to multiply (geometric mean), rather to sum (arithmetic mean) each indicator in order to reflect indicators imperfect substitutability. The validation of an assistance targeting system could be performed through a detailed analysis of exclusion/exclusion errors between each of the vulnerability scoring approaches. Diagram: Summary of potential targeting approaches 4.3 What data can be used? Subjective scoring relies on the input of experts to produce a qualitative judgment. Statistical scoring, on the other hand, relies on quantified characteristics of the prospect’s portfolio history recorded in a database. It uses a set of rules and statistical techniques to forecast risk as a probability. TABLE 1. Comparison of Subjective and Statistical Scoring Dimension Subjective Scoring Statistical Scoring Source of knowledge Experience of loan officer and organization Quantified portfolio history in database Consistency of processVaries by loan officer and day-to-day Identical loans scored identically Explicitness of processEvaluation guidelines in office; sixth sense/gut feeling by loan officers in fieldMathematical rules or formulae relate quantified characteristics to riskProcess and productQualitative classification as loan officer gets to know each client as an individualQuantitative probability as scorecard relates quantitative characteristics to riskEase of acceptanceAlready used, known to work well; MIS and evaluation process already in placeCultural change, not yet known to work well; changes MIS and evaluation processProcess of implementationLengthy training and apprenticeships for loan officersLengthy training and follow-up for all stakeholdersVulnerability to abusePersonal prejudices, daily moods, or simple human mistakesCooked data, not used, underused, or overusedFlexibilityWide application, as adjusted by intelligent managersSingle application, forecasting new type of risk in new context requires new scorecardKnowledge of trade-offs and “what would have happened”Based on experience or assumedDerived from tests with repaid loans used to construct scorecard Statistical scoring models are:• Empirical. Based on a rigorous statistical analysis that derives empirical ways to distinguish between more and less creditworthy consumers using data from applicants within a reasonable preceding period.• Statistically valid. Developed and validated based on generally accepted statistical practices and methodologies.5BENEfItS of crEdIt ScorINg• Periodically revalidated. Re-evaluated for statistical soundness from time to time and adjusted, as necessary, to maintain or increase its predictive power. 4.3.1 Calibration using expert opinions First option, weighting sources can be personal views of experts, societal views estimated through surveys or public opinion polls. 4.3.2 Calibration using statistically representative dataset it’s possible to define a proxy indicator for vulnerability (for instance expenditure per capita as used in the Proxy Means Testing, but also Population Group based on a population segmentation exercise) and from there use regression and other predictive models to get a formula. The main limitation from this approach consists in the assumptions behind the quality of the proxy: for instance, an household can have a good income precisely because children in the household are working. The second limitation for this approach are that weight calculated from within the data (i.e based on respondent) as a function of the data-set, meaning the resulting scores are highly dependent on the representativeness of the respondent…. there are other non-subjective weighting schemes (i.e. task of assigning weights), based on data-driven approaches that do not depend on value judgments or proxies while allowing for analytically sound and transparent process. Though most data-driven techniques such as Principal Component Analysis (PCA), Factor Analysis, Structural Equation Model or Benefit-of-the-Doubt, assumes the observed variables to be continuous even when they are in fact binary or categorical, as this is the case in most household survey questionnaire (cf. On Construction of Robust Composite Indices by Linear Aggregation, Mishra, 2008). "],["risks-when-calibrating-vulnerability-scores.html", " 5 Risks when calibrating vulnerability scores 5.1 There’s no magic formula 5.2 Building consensus 5.3 Including and communication with communities", " 5 Risks when calibrating vulnerability scores 5.1 There’s no magic formula 5.2 Building consensus 5.3 Including and communication with communities "],["budget-allocation.html", " 6 Budget allocation 6.1 Selecting experts 6.2 Speed-up consultation with quadratic voting 6.3 Restitution of results", " 6 Budget allocation 6.1 Selecting experts 6.2 Speed-up consultation with quadratic voting 6.3 Restitution of results "],["conjoint-analysis.html", " 7 Conjoint analysis 7.1 Principle of opinion reverse engineering 7.2 Cutomise the indicators 7.3 Setting up the consultation", " 7 Conjoint analysis 7.1 Principle of opinion reverse engineering 7.2 Cutomise the indicators 7.3 Setting up the consultation "],["analytic-hierarchy-process.html", " 8 Analytic Hierarchy Process 8.1 Defining weights through expert judgment 8.2 The Analytic Hierarchy Process (AHP) 8.3 Limitation of AHP 8.4 How to? A step by step approach 8.5 Define vulnerability criteria 8.6 Build the expert consultation form 8.7 Form 8.8 3. Generate the AHP file from the collected data 8.9 4. Run AHP algorithm 8.10 5. Review results 8.11 6. Apply the formula", " 8 Analytic Hierarchy Process 8.1 Defining weights through expert judgment How expert can come up with values for the weight? How to reach agreement among expert on the suggested values? Is there an alternative to lengthy consensus building? Often teams of expert suffer from non-aligned goals, power politics, group dynamics and lack of mutual understanding. How to build consensus on complex decisions in order to raise sufficient confidence in decision outcomes? 8.2 The Analytic Hierarchy Process (AHP) Structured technique for organizing and analyzing complex decisions, based on mathematics and psychology Comprehensive and rational framework to organize feeling, intuition &amp; logic for structuring group decision making. Rather than prescribing a “correct” decision, the AHP helps decision makers find one that best suits their goal and their understanding of the problem Comparison is made to define priorities between 2 alternatives based on decision-maker’s feeling of priority dues to importance, preference and likelihood of influence. This breaks down complex decision into small judgement Developed in the 70’s by Thomas Saaty in Wharton Business School. Decision Making for Leaders: The Analytic Hierarchy Process for Decisions in a Complex World 8.3 Limitation of AHP Assumes a minimum level of judgment consistency among experts Limited number of criteria to minimize the number of pairwise comparison estimation Data should be available for all criteria Assumes that when new alternatives are added to a decision problem, the ranking of the old alternatives is not changing 8.4 How to? A step by step approach Define vulnerability criteria Build the expert consultation form Generate the AHP file from the collected data Run AHP algorithm Review results Apply the formula 8.5 Define vulnerability criteria List potential criteria that would contribute to vulnerability within the current context. Note that criteria can be grouped togehter using hierarchy. Establish treehold for criteria so that they can be formulated as simple binary questions Criteria should be saved in a configuration file using the format here data/criteria.csv. 8.5.1 Criteria without hierarchy In this case N*(N-1)/2 pairs to review: 5 criteria -&gt; 10 comparisons Criteria-Code Criteria-Level-1-label Criteria-Level-2-label age Age of head of household is above 50 gender Gender of head of household is female size Household size is above 5 needs Occurrence of Specific needs assitance Do not Receive assistance PS: 6 criteria -&gt; 15 comparison, 7 criteria -&gt; 24 comparisons, 8 criteria -&gt; 28 comparisons, 9 criteria -&gt; 36 comparisons 8.5.2 Criteria with hierarchy In this case 6 pairs to review… Criteria-Code Criteria-Level-1-label Criteria-Level-2-label age Demography Age of head of household is above 50 gender Demography Gender of head of household is female size Demography Household size is above 5 needs Occurrence of Specific needs assitance Do not Receive assistance 8.6 Build the expert consultation form A form will allow to collect from expert priorities between criteria by making a series of judgments based on pairwise comparisons: Collect judgment for all pairwise comparison and each expert Ranking Scales for Criteria Use the script 1-Build-xlsform.R to build a xlsform file based on criteria defined above. 8.7 Form The form can be used within UNHCR Kobo server. Experts can be humanitarian case workers that are used to assess vulnerability. See an example here 8.8 3. Generate the AHP file from the collected data Once the selected experts (aka. decision-makers) have filled the online form , data can be exported from UNHCR Kobo server in csv format. Use the script 2-build-hierarchy.R to build a xlsform file to create the AHP file. This create the file that format correctly the pairwise preferences of each decision-makers to run the next step. 8.9 4. Run AHP algorithm Calculation done using R statistical language. Synthesize these judgments to yield a set of overall priorities Check judgments consistency (consistency ratio) Compute weights for each expert Mathematical calculations to convert these judgments to priorities for each of the four criteria Note: Some proprietary software options are also available but would require a Data Protection Impact Assessment before using them. 8.10 5. Review results Knit the 3-final-report.Rmd to get the report. You can see an example here. An interactive interface is available to interact with results. Lack of consistency is often observed If consistency ratio is above 0.1, then judgement are untrustworthy because they are too close to randomness -&gt; exercise needs to be repeated or abandonned. 8.11 6. Apply the formula Calculate mean relative weight Apply the vulnerability formula Collect data on each criteria for all household Apply weight to each record for the different criteria to get the vulnerability level of each household "],["vulnerability-proxy-regression.html", " 9 Vulnerability proxy Regression 9.1 ", " 9 Vulnerability proxy Regression 9.1 "],["data-envelopment-and-deprivation.html", " 10 Data Envelopment and Deprivation 10.1 What is deprivation analysis?", " 10 Data Envelopment and Deprivation 10.1 What is deprivation analysis? Synthetic scores of multiple deprivation mdepriv is a R package for combining binary, continuous and suitably transformed ordinal items/indicators of deprivation into synthetic measures of deprivation. As such, it is a tool of poverty analysis. It is suitable also for generating composite measures of severity and vulnerability in the humanitarian realm. The R implementation translates the original Stata version by Pi Alperin &amp; Van Kerm (2009), with additional features (notably, non-integer sampling weights are admitted). mdepriv returns unit-level synthetic scores of multiple deprivation and their statistical summaries. It offers several methods for determining item/indicator weights in response to user preferences for rewarding better discrimination and penalizing redundancy. mdepriv is particularly appropriate in situations where the underlying concept of deprivation / severity / vulnerability is intuitively multi-dimensional, but the structure of dimensions is poorly understood; plausibly they overlap, i.e. they reinforce each other to unknown degrees. Also, the measures produced under mdepriv do not presume normative standards (e.g., poverty lines). There are no a-priori cut-offs of the kind that are fundamental to multi-dimensional poverty measures in the Alkire-Foster tradition (implemented in R for example in the functions svyafc and svyafcdec of the package convey). Shortfall indicators (e.g., years of basic education missed) can be used the same way as non-normative ones (e.g., workdays lost to illness). # install package devtools if not yet installed # install.packages(&quot;devtools&quot;) # install fast from GitHub without vignettes (not recommanded) # devtools::install_github(&quot;a-benini/mdepriv&quot;) Fundamentally, the four methods Equi-proportionate Desai &amp; Shah (1988) Cerioli &amp; Zani (1990) Betti &amp; Verma (1998) differ by their increasing sensitivity to deprivations / adverse conditions suffered by the poorest / most oppressed units (individuals, households, communities). The idea is to weight more strongly specific deprivations / adverse conditions that the more advantaged units have overcome, but which are still afflicting those at the bottom. Typically, in poverty studies, this makes good sense with durable household assets, which are observed as dichotomous “has / does not have” and recorded as binary (0/1) variables. In humanitarian assessments it is less common that the severity of a lacking / suffering / threat is inversely proportionate to its prevalence. When prevalence-dependent weighting is not appropriate, mdepriv gives the user three options: Equi-proportionate weighting Unequal weights chosen for substantive considerations Switching off prevalence-sensitivity This third option is meaningful primarily in combination with the Betti-Verma method. This method deserves particular attention. Its defining feature is a double-weighting algorithm: The first weighting factor gauges the discriminating power of an item / indicator through its coefficient of variation (= standard deviation / mean). For dichotomous items / indicators, this implies high sensitivity to prevalence (the C.o.V. grows exponentially as the proportion tends towards zero). For continuous ones, higher C.o.V.s imply higher information content. The second weighting factor results from the correlations among the items / indicators. Those correlated strongly positively with most others are considered more highly redundant and are penalized with lower weights. Those with comparatively low positive or negative sums of correlation coefficients are considered capturing more unique aspects of deprivation / humanitarian conditions and are rewarded with higher weights. Betti-Verma is the only one among the four methods sensitive to the information content of continuous items / indicators. mdepriv automatically computes the weight of each item / indicator proportionate to the product of its two weighting factors. The mdepriv function makes the second weighting factor available also for the other three methods, but not all combinations are practically meaningful. mdepriv automatically recognizes the appropriate type of correlations between pairs of items / indicators, but the user can impose a particular type collectively on all pairs (rarely meaningful!). When the user opts for double-weighting (other than in Betti-Verma, where it is the default), the options have to be specified for both factors. mdepriv notation for the first factor is wa, for the second it is wb. However, not all combinations are practically meaningful. Recommended combinations depend on the analytic objective. Plausibly, the most relevant are: Objective First weighting factor (wa) Second weighting factor (wb) Indifferent to prevalence (dichotomous items) and to information content (continuous). But controlling for redundancy is important. Equi-proportionate on Items are all dichotomous. Limited sensitivity to low prevalence desired. Not controlling for redundancy. Desai-Shah off Items are all dichotomous. High sensitivity to low prevalence desired. Not controlling for redundancy. Betti-Verma off All items are continuous, and controlling for redundancy is important. Betti-Verma on Items are mixed dichotomous / continuous. Indifferent to prevalence of the dichotomous, but concerned for information content of the continuous. Redundancy control is important. i.e. Two-level deprivation / severity model: Level 1: Combine all dichotomous items, save scores as one more continuous indicator for the second level. Equi-proportionate on Level 2: Combine continuous items and indicator saved from first level. Produces aggregate deprivation / severity statistic. Betti-Verma on The Cerioli-Zani model appears to be primarily of historic interest. It was one of the first to pursue the so-called fuzzy-set approach to multi-dimensional poverty measurement, which Betti and Verma subsequently deepened. The interested user may consult the reader edited by Lemmi and Betti (2006), but familiarity with fuzzy sets is not required for the understanding and application of mdepriv. As a final introductory remark, it should be said that the Betti-Verma method is particularly appropriate when a concept (deprivation, severity of conditions, etc.) has many aspects, its dimensionality is not well understood, and classical methods to unravel the dimensions (e.g., factor analysis) are likely distorted by redundancies among the available indicators. The following focuses on the technical handling of the mdepriv package. Context and rationale are not discussed here. The purpose is to walk the user through the manifold arguments and outputs of the core function mdepriv. Familiarity with the basics of R is presumed. Still, things are kept at a pretty low skill level so that users with little R experience can follow. The code provided is intended as copy-and-paste material, which users can modify for practice or for real-world data analysis. Chiefly we will use the simulated dataset simul_data with 100 observations, which are enough to demonstrate functionality. To showcase a two-level deprivation model we put the dataset MSNA_HC to use. Both datasets are part of the mdepriv-package; thus they do not require further sourcing. "],["item-response-theory.html", " 11 Item Response Theory 11.1 Vulnerability as a “latent” variable 11.2 Building composite indicators with IRT", " 11 Item Response Theory This tutorial is adapted from 2 articles: MultiLCIRT: An R package for multidimensional latent class item response models Variable weighting via multidimensional IRT models in Composite Indicators construction Thanks to Simone Del Sarto from University of Perugia, Italy for the guidance on this document. 11.1 Vulnerability as a “latent” variable A major task in the measurement of complex and latent household vulnerability dimensions phenomena such as deprivation (or Basic Needs), wealth (or Coping capacity) and ability (or Well-being) consists of summarising information available from a set of dichotomous or ordinal questions (also referred as items) from an household survey questionnaire. For example: Deprivation (or Basic Needs), is assessed by collecting data on the extent to which households possess certain commodities, engage in certain activities or are subject to financial pressures. The responses of individuals to deprivation item questionnaires constitute the manifest or observed indicators. (cf. Item response theory and the measurement of deprivation, Szeles and Fusco, 2013) Wealth (or Coping capacity) is a latent concept to be derived from observable assets, and measures of wealth are calculated from a set of assets a household possesses (cf. Measuring Household Wealth with Latent Trait Modelling: An Application to Malawian DHS Data, Vandemoortele, 2014). 11.2 Building composite indicators with IRT Item Response Theory (IRT) are specific type of statistical modeling that allows to address this complex challenge of building data-driven vulnerability scores without the use of proxy indicators. The assumptions that IRT approaches allows for are closer to the operational reality and needs: Latent phenomenon → not directly observable through a proxy, meaning that vulnerability is not directly measurable . Latent variable → assumed to have a discrete distribution rather than continuous vulnerability scales. Phenomenon manifestation → response pattern to the items of a questionnaire rather to profile of respondents. Summary of the phenomenon → composite indicators rather than predicted scores. Item Response Theory (IRT) (also known as latent trait theory, strong true score theory, or modern mental test theory) is a paradigm for the design, analysis, and scoring of tests, questionnaires, and similar instruments measuring abilities, attitudes, or other latent variables. It is a theory of testing based on the relationship between individuals’ performances on a test item and the test takers’ levels of performance on an overall measure of the ability that item was designed to measure. IRT models the response of each respondant of a given ability to each item in the test. The term item, here is generic, covering all kinds of informative items. They might be multiple choice questions that have incorrect and correct responses, but are also commonly statements on questionnaires that allow respondents to indicate level of agreement (a rating or Likert scale), or patient symptoms scored as present/absent, or diagnostic information in complex systems. The main advantage of the discrete approach consists in the possibility of clustering the statistical units into homogeneous groups (latent classes): units (people, refugees and so on) in the same class share very similar characteristics in terms of the investigated (multidimensional) latent trait. Hence, this model would also allow us to classify refugees in similar groups. Such model can support prioritization needs as it assigns a score to each group, so that it is possible to highlight the most/least vulnerable groups of refugees and/or sketch several refugees’ profiles according to the various dimensions of it. Composite indicators can be built using IRT using the following procedure: Step 1 : Assess dimensionality within the variables of the data-set → Multidimensional Latent Class IRT model + clustering algorithm Step 2 : Adoption the best model for assigning weights to the test items. This steps also allows to account for dimensionality (clusters) within respondents. Step 3 : Item aggregation using the weights obtained at the previous step → construction of a composite indicator for each dimension 11.2.1 Step 0: Data Preparation Data are loaded in a data frame and converted in a matrix, corresponding to the unit-by-unit response configurations. To make the further estimation of the proposed models and clustering of items faster perform the analyses after aggregating the original records which correspond to the same response pattern so as to obtain a matrix with a record for each distinct response configuration (rather than for each statistical unit). The function function aggr_data is then applied to this matrix. Output from function is: data_dis: matrix of distinct configurations → S (used after in model estimation); freq : vector of corresponding frequencies → yv (used after in model estimation); label: index of each original response configuration among the distinct ones. The data-set in this reports contains the responses of a sample of 201 / 201 records to 14 / 196 binary items. Tableplot is a powerful visualization method to explore and analyse large multivariate datasets. The representation below are used to help in the understanding of the data, explore the relationships between the variables, discover strange data patterns, and check the occurrence and selectivity of missing values. 11.2.2 Step 1: Clustering algorithm / Dimensionality assessment The first steps aims at grouping variables measuring the same latent construct in the same cluster Investigating the best number of latent classes (parameter k) is done through Hierarchical clustering of items based on the Rasch model. The function class_item is used, it can take a long execution time. The classification is based on a sequence of likelihood ratio tests between pairs of multidimensional models suitably formulated. The dendrogram below highlights three dimensions composing the multidimensional construct. Considering the item contents, the assessed dimension can be interpreted from a narrative point of view. The following tables allows to interpret the clustering: The first two columns (entitled items) indicate items or groups collapsed at each step of the clustering procedure, the third column(deviance) reports the corresponding LR statistic, the fourth column(df)reports the number of degrees of freedom, the fifth (p-value) reports the p-value, and the last column (newgroup) contains the new group of items that is formed at each step. 11.2.3 Step 2: Model selection The second step is a selection procedure based on estimation of ordinal polytomous multidimensional LCIRT model. The formulation of a specific model in the class of multidimensional Latent Class (LC) IRT models univocally depends on: number of latent classes k, adopted parameterization in terms of link function , constraints on the item parameters , and number of latent dimensions (s) and the corresponding allocation of items within each dimension Parameter estimation for multidimensional IRT models based on discreteness of latent traits is performed through function est_multi_poly requires the following main input: S: matrix of all response sequences observed at least once in the sample and listed row-by-row. Usually,S is a matrix of type data_dis obtained by applying function aggr_data to the original data. Missing responses are allowed and they are coded as NaN; yv: vector of the frequencies of every response configuration in S corresponding to the output freq of function aggr_data (default value is given by a vector of ones, implying a unit weight for each record in S); k : number of latent classes - defined in the step 1; X : matrix of observed covariates, having the same dimension as S (default value is NULL, indicating the absence of covariates in the study); start: method of initialization of the algorithm: 0 ( = default value) for deterministic starting values, 1 for random starting values, and 2 for arguments given bytheuser. If start = 2 ,we also need to specify as input the initial values of weights, support points, and discriminating an ddifficulty item parameters (using additional input arguments that are set equal to NULL otherwise); link : type of link function: 0 (= default value) for the standard Latent Class model (i.e., no link function is specified),1 for global logits, and 2 for local logits. In the case of dichotomous responses, it is the same to specify link = 1 or link = 2; disc : indicator of constraints on the discriminating item parameters: 0 (= default value) if γj= 1, j=1 ,…, r, and 1 otherwise; difl : indicator of constraints on the difficulty item parameters: 0 (= default value) if difficulties are free and 1 if βjx= βj+ τx multi : matrix with a number of rows equal to the number of dimensions and elements in each row equal to the indices of the items measuring the dimension corresponding to that row. Cases where dimensions are measured by a different number of items are allowed, and the number of columns of matrix multi corresponds to the number of items in the largest dimension. Function est_multi_poly supplies the following output: Piv: optional object of type matrix containing the estimated weights of thelatent classes subject-by-subject (the weights may be different across subjects in the presence of covariates); Th: estimated matrix of ability levels (support points) for each dimension (= row of matrix Th) and latent class (= column of matrix Th); Bec : estimated vector of difficulty item parameters (split in two vectors if difl = 1); gac : estimated vector of discriminating item parameters; if disc = 0 (Rasch-type model), all values of vector gac are constrained to 1; fv : vector indicating the reference item chosen for each latent dimension; Phi : optional object of type array containing the conditional response probabilities (see Eq.(1)) for every item and latent class. The array is made of as many matrices as the latent classes; moreover, the j -th column of each of such matrices refers to item j , where as the x-th row of each matrix refers to the x- th responsecategory(x = 0,…, lj − 1) of item j. In the case of items differing in the number of response categories, zeros are included in the corresponding cells; Pp : optional object of type matrix containing the posterior probabilities of belonging to latent class c (column c of the Pp matrix), given the response configuration (row of the Pp matrix); lk : log-likelihood at convergence of the EM algorithm; np : number of free parameters; aic : Akaike Information Criterion index (Akaike,1973); bic : Bayesian Information Criterion index (Schwarz,1978) 11.2.3.1 Number latent classes to consider Checking here the optimal value of parameter k Model Comparison log-lik. np BIC model1 -3,153.151 42 6,529.040 model2 -2,814.635 85 6,080.051 model3 -2,677.822 128 6,034.468 model4 -2,645.435 171 6,197.736 The model with lowest BIC is retained (i.e. k = 3). 11.2.3.2 Define parameterization on link function To define if Global or local logit shall be used, we need to identify the optimal value of parameter link (1= Glocal logit, 2 = Local logit) Model Comparison log-lik. np BIC model1 -2,726.348 72 5,834.534 model2 -2,741.321 72 5,864.479 The model with lowest BIC is retained (i.e. link = 1). 11.2.3.3 Constraints on the item parameters: Likelihood ratio To test between nested multidimensional LC IRT models, we can compare different multidimensional model: a restricted model against a larger multidimensional model based on a higher number of dimensions. A typical example is testing a unidimensional model (and then the hypothesis of unidimensionality) against a bidimensional model through function test_dim. We will retain here the model with the smaller BIC value - Retained value for link = 1 11.2.3.4 Test of unidimensionality Once the global logit has been chosen as the best link function, we carry on with the test of unidimensionality. An LR test is used to comparemodels which differ in terms of the dimensional structure, all other elements being equal (i.e. free item discriminating and difficulty parameters), that is, * (i) a graded response model (GRM) with an r-dimensional structure, * (ii) a graded response model (GRM) with a bidimensional structure (i.e., anxiety and depression), as suggested by the structure of the questionnaire, and * (iii) a graded response model (GRM) with a unidimensional structure (i.e., all the items belong to the same dimension). For this, models are calculated with different parameters: * Difficulty levels (Free or Constrained, ie. constant or non-constant) difl. * Discriminating indices (Free or Constrained, ie. constant or non-constant) disc. Model Comparison log-lik. np BIC LR(vs. model1) df p-value model1 -2,731.893 59 5,776.682 model2 -2,795.570 33 5,766.149 127.353 26 0 model3 -2,741.285 46 5,726.521 18.782 13 0.130 Model Comparison log-lik. np BIC LR(vs. model1) df p-value model1 -2,741.285 46 5,726.521 model2 -2,844.518 20 5,795.102 206.467 26 0 Model Comparison Class 1 Class 2 Class 3 Dimension 1 -0.775 1.184 3.419 prob 0.342 0.491 0.167 11.2.4 Step 3: Items aggregation using the weights The discrimination parameters express the informative capacity of a variable and its relative importance within sub-dimensions of the latent variables (as the model is multidimensional): so that the weight of a variable expresses the relative importance of that variable in the dimension it belongs to. Weights are extracted from discrimination parameters, estimated through a Multidimensional IRT model, using a 2PL parametrisation Two composite indicators can be calculated: Unweighted score (raw relative frequency of correct response) Weighted score, using ˆ γ j (and their transformation) for weighting the items 11.2.4.1 Multidimensional scores gamma_hat: \\(\\hat{\\gamma}_j\\) (weights) from the model selected in the step above. Since two dimensions are supposed, these weights can be divided into two groups A useful thing to do is to rescale the parameters (within each dimension), so that the most discriminating item (for each dimension) has gamma_hat:\\(\\hat{\\gamma}_j = 1\\) and the other items have \\(\\hat{\\gamma}_j &lt; 1\\). This is obtained by dividing each vector by its maximum element. We can now use scaled discriminating item parameters parameters as weights. Since these two sets of parameters are dimension-specific so they are not are not comparable. Two different composite indicators can be constructed at this stage: one for the first dimension (dim1) and one for the second dimension (dim2). Note that dividing by the weight sum (sum(gamma_hat1)) is not necessary, it depends on the type of indicator you need (in terms of sum or average). These indicators can be compared with the unweighted counterpart. Final Weight CI1w CI1unw CI2w CI2unw 1 1.127 1.143 1.173 1.143 2 0.576 0.571 0.715 0.714 3 1.379 1.429 0.873 0.857 4 0.671 0.714 0.576 0.571 5 0.279 0.286 0.432 0.429 6 0.549 0.571 0.432 0.429 Visualisation of resulting composite indicator 11.2.4.2 Sinle composite indicator One wish to have a unique composite indicator, computed by using the entire response pattern of each unit. In this case, the discrimination parameters need to be made comparable across dimensions. Then, we have to compute \\(\\gamma_j^*\\). First, we need to compute gamma_hat: \\(\\hat{\\sigma}_d\\) Then, we can compute gamma_hat: \\(\\gamma_j^* = \\hat{\\sigma}_d \\hat{\\gamma}_j, j \\in \\mathcal{J}_d\\). As the standard deviation of the latent traits is taken into consideration, the item discriminations are now comparable. For example, we could rank the items according to their discrimination. Hence, a unique composite indicator can be built using these last weights. Finally, one could rescale these last parameters (in order to obtain those denoted by \\(w_j\\) in the paper). Final Weight item discr unique 3 7 0.867 0.830 14 14 1.003 0.764 7 12 1.016 0.811 12 9 1.119 0.804 1 2 1.128 1 2 6 1.145 0.775 10 4 1.188 0.587 9 3 1.199 0.813 4 8 1.201 0.758 5 10 1.213 0.821 8 1 1.226 0.969 13 13 1.281 0.688 6 11 1.432 0.867 11 5 1.477 0.679 If the data at issue are multilevel (e.g., refugees nested in different neighborhoods/villages/camps districts), the model can be extended to cluster high-level units (i.e. neighborhoods/villages/camps districts) as well. Further, covariates can be included to check the effects (if any) of individual (or higher level) covariates in the units’ class membership probabilities. Additionally, Discrete Multidimensional Two-Tier IRT Model, an extension of the previous models can be explored to account for the double dependency of single items on more than one dimension of the Latent Variable. In further research, the proposed procedure can therefore be extended through a classification of higher-order units in homogeneous groups - instead of ranking them one by one - that would take advantage of the latent class part of the described method, and account for the multilevel structure of the data. So basically not only the analysis would provide the vulnerability score of household but also account for a potential geographic effect within their vulnerability profile. Another element of research includes to define the impact of sampling on the resulting weights. "],["robustness-and-sensitivity-analysis.html", " 12 Robustness and Sensitivity analysis 12.1 ", " 12 Robustness and Sensitivity analysis 12.1 "],["eligibility-and-prioritization.html", " 13 Eligibility and Prioritization 13.1 Eligibility", " 13 Eligibility and Prioritization 13.1 Eligibility 3 operation-specific suggested scores &amp; formula based on composite indicators for:​ Susceptibility to risk Capacity to cope Ability to be resilient Numeric scores from 0-100 = thresholds adjustable to support prioritization decisions​ Scores can be mixed or not as required "],["conclusion.html", " 14 Conclusion 14.1 ", " 14 Conclusion 14.1 "]]
